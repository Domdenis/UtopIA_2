"""
UtopIA ‚Äî Node Chat Clinique
G√©n√®re des questions cibl√©es sur le profil patient et collecte les r√©ponses.
"""

import json
import re
from anthropic import Anthropic
from graph.state import PatientState

SYSTEM_PROMPT = """Tu es UtopIA, un ergoth√©rapeute expert en pr√©conisation de fauteuils roulants (VPH).
Tu m√®nes un entretien clinique structur√© pour compl√©ter l'√©valuation d'un patient avant de faire tes pr√©conisations.

Tes questions sont :
- Pr√©cises, cliniques, directement li√©es au profil sp√©cifique du patient
- Organis√©es par th√®me : propulsion, contr√¥le postural, transferts, environnement, activit√©s
- Formul√©es de fa√ßon claire pour un ergoth√©rapeute
- Progressives : chaque r√©ponse peut orienter la question suivante

Tu poses UNE question √† la fois, avec √©ventuellement des sous-points.
Tu utilises les r√©ponses pr√©c√©dentes pour affiner les questions suivantes.
Tu indiques quand tu as suffisamment d'informations pour faire des pr√©conisations."""


def generate_first_question(patient: PatientState, api_key: str, vectorstore=None) -> str:
    """G√©n√®re la premi√®re question cibl√©e selon le profil."""
    client = Anthropic(api_key=api_key)

    rag_section = ""
    if vectorstore:
        try:
            from rag.retriever import search, format_context
            docs = search(
                "evaluation capacites fonctionnelles fauteuil roulant propulsion transfert",
                k=3, vectorstore=vectorstore
            )
            if docs:
                rag_section = "R√©f√©rences cliniques :\n" + format_context(docs)
        except Exception:
            pass

    lines = [
        "Voici le profil d'un patient pour lequel je dois compl√©ter l'√©valuation avant de pr√©coniser un VPH.",
        "",
        patient.to_context_summary(),
        "",
        "Sur la base de ce profil, pose la PREMI√àRE question clinique la plus importante pour orienter",
        "le choix du type de fauteuil (manuel, √©lectrique, avec assistance...).",
        "",
        "La question doit √™tre :",
        "- Tr√®s sp√©cifique √† CE patient (cite son pr√©nom, sa pathologie, sa situation)",
        "- Centr√©e sur le point le plus d√©terminant pour le choix du VPH",
        "- Avec des sous-points si n√©cessaire (3-4 maximum)",
        "",
        "Commence directement par la question, avec une courte introduction contextuelle.",
        "Utilise des emojis üëâ pour les sous-points.",
    ]
    if rag_section:
        lines.append("")
        lines.append(rag_section)

    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=600,
        system=SYSTEM_PROMPT,
        messages=[{"role": "user", "content": "\n".join(lines)}]
    )
    return response.content[0].text


def generate_next_question(
    patient: PatientState,
    api_key: str,
    conversation_history: list,
    vectorstore=None
) -> dict:
    """
    G√©n√®re la question suivante bas√©e sur l'historique de conversation.
    Retourne : {"question": "...", "termin√©": bool, "synthese": "..."}
    """
    client = Anthropic(api_key=api_key)

    # Construire l'historique format√©
    history_str = ""
    for msg in conversation_history:
        role = "UtopIA" if msg["role"] == "assistant" else "Ergoth√©rapeute"
        history_str += role + " : " + msg["content"] + "\n\n"

    lines = [
        "Profil patient :",
        patient.to_context_summary(),
        "",
        "Entretien clinique r√©alis√© jusqu'ici :",
        history_str,
        "Sur la base des r√©ponses obtenues :",
        "1. As-tu suffisamment d'informations pour faire des pr√©conisations VPH pr√©cises ?",
        "2. Si oui, r√©ponds en JSON : {\"termine\": true, \"synthese\": \"r√©sum√© des points cl√©s en 3-4 phrases\"}",
        "3. Si non, pose la prochaine question clinique la plus importante.",
        "   R√©ponds en JSON : {\"termine\": false, \"question\": \"ta question avec sous-points\"}",
        "",
        "Maximum 5 questions au total. Si on a d√©j√† 4 √©changes ou plus, conclure obligatoirement.",
        "R√©ponds UNIQUEMENT en JSON valide.",
    ]

    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=600,
        system=SYSTEM_PROMPT,
        messages=[{"role": "user", "content": "\n".join(lines)}]
    )

    text = response.content[0].text
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except Exception:
            pass

    # Fallback
    nb_exchanges = len([m for m in conversation_history if m["role"] == "assistant"])
    if nb_exchanges >= 4:
        return {"termine": True, "synthese": "Informations suffisantes collect√©es pour la pr√©conisation."}
    return {"termine": False, "question": text}


def build_chat_synthesis(patient: PatientState, api_key: str, conversation_history: list) -> str:
    """Synth√®se finale de l'entretien pour enrichir le PatientState."""
    client = Anthropic(api_key=api_key)

    history_str = ""
    for msg in conversation_history:
        role = "UtopIA" if msg["role"] == "assistant" else "Ergoth√©rapeute"
        history_str += role + " : " + msg["content"] + "\n\n"

    lines = [
        "Sur la base de cet entretien clinique compl√©mentaire :",
        "",
        history_str,
        "R√©dige une synth√®se clinique structur√©e en 4-5 phrases qui r√©sume :",
        "- Les capacit√©s de propulsion et d'endurance",
        "- Le contr√¥le postural",
        "- Les capacit√©s de transfert",
        "- Les contraintes environnementales cl√©s",
        "- Les √©l√©ments d√©terminants pour le choix du VPH",
        "",
        "Cette synth√®se sera int√©gr√©e directement dans le dossier patient.",
    ]

    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=500,
        system=SYSTEM_PROMPT,
        messages=[{"role": "user", "content": "\n".join(lines)}]
    )
    return response.content[0].text
